[
["index.html", "Introducción al scraping y a la minería de texto Preámbulo", " Introducción al scraping y a la minería de texto Olivier Nuñez 2018-06-01 Preámbulo Internet es una fuente inagotable de información y datos. Desafortunadamente, la mayoría de las veces, los datos están integrados a una pagina web y no pueden ser extraídos directamente para su análisis estadístico. Cuando el volumen de datos es pequeño, es posible copiarlos “a mano”. Pero si la cantidad de datos es demasiado grande o si están dispersos en un gran número de páginas, este método no es factible. Esta introducción tiene como objetivo explicar cómo extraer esta información utilizando herramientas de R y mostrar algunas operaciones de procesamiento y análisis de datos textuales. Lo que sigue requiere los paquetes rvest y tidytext: install.packages(c(&quot;rvest&quot;,&quot;tidytext&quot;),dep=TRUE) "],
["scraping-con-r.html", "1 Scraping con R 1.1 Qué se puede “rascar” de la web? 1.2 Formato HTML 1.3 Identificar elementos de interés en una página 1.4 El paquete rvest 1.5 Navegación", " 1 Scraping con R 1.1 Qué se puede “rascar” de la web? “Si puedes verlo, puedes rascarlo” Cualquier cosa en una página web: Tablas Texto Vínculos Metadatos (tiempo de publicación, actualización, …) Atributos de página web (colores, fuentes, tamaño de texto utilizado, ..) Imágenes 1.2 Formato HTML El código HTML está compuesto de etiquetas predefinidas que le dicen al navegador cómo mostrar los datos. A menudo, estas etiquetas están anidadas: &lt;ul&gt; &lt;li&gt;Articulo 1&lt;/li&gt; &lt;li&gt;Articulo 2&lt;/li&gt; &lt;/ul&gt; Dará: Artículo 1 Artículo 2 La etiqueta “&lt;ul&gt;” indica una lista desordenada y “&lt;li&gt;” indica un elemento de la lista. Una etiqueta que comienza con una barra inclinada finaliza la etiqueta anterior de ese tipo. HTML se vuelve más complicado, pero entender las etiquetas es suficiente para comenzar a rascar. 1.3 Identificar elementos de interés en una página Puede ser útil ilustrar brevemente algunas prácticas para identificar elementos en una página de la cual uno desea extraer los datos. En este sentido, la mayoría de los navegadores web ofrecen no solo la posibilidad de ver el código fuente de una página, sino también analizar los elementos. Esta función de inspección suele estar disponible directamente en el menú contextual del navegador. Se señala el elemento que nos interesa, se hace clic con el botón derecho y se elige el elemento del menú contextual que permite analizarlo. Captura de pantalla de la pagina de IMDB dedicada a la película “Amanece que no es poco” Aquí hay una lista de criterios para la identificación de los elementos: ID de atributo : si el elemento tiene un atributo id (caracterizado en el identificador con el carácter #), se supone que este atributo es exclusivo del elemento. Por lo tanto, es muy útil para extraerlo de la página, pero no es adecuado para extraer elementos recursivos (por ejemplo, varios párrafos), ya que cada uno debe tener una identificación única. Clases : Las clases son una buena forma de identificar elementos recursivos en el mismo nivel jerárquico. Por ejemplo, los comentarios de blog a menudo comparten la misma clase (por ejemplo, class = “comment”). Para maximizar la probabilidad de identificar el elemento correcto, en el caso de que múltiples elementos en diferentes ubicaciones en la página tengan la misma clase, este criterio puede estar asociado con el nombre de la etiqueta (por ejemplo, div.comment). Posición jerárquica : el análisis de elementos a menudo propone la posición relativa a la raíz del DOM ocupado por el elemento seleccionado. Se usa si las etiquetas nunca tienen atributos de identificación o clase. 1.4 El paquete rvest Este paquete de “cosecha” extrae contenidos de páginas web en HTML/XML usando la sintaxis de los selectores de CSS. Por ejemplo, un párrafo que está directamente dentro de una etiqueta de tipo div puede identificarse usando la notación div &gt; p. Este paquete es bastante simple, porque no tiene muchas funciones, pero proporciona las principales características necesarias para la identificación y extracción de datos en una página, así como algunas funciones que permiten explorar las páginas emulando un navegador web. 1.4.1 Cargar la pagina Para ilustrar el uso de rvest, vamos a extraer información sobre la película “Amanece, que no es poco” de su pagina en el IMDb. require(rvest) amanece &lt;- read_html(&quot;http://www.imdb.com/title/tt0094641/&quot;) La función read_htmlpermite importar en R el contenido html de una página web. El argumento principal de esta función es la dirección de la pagina web ( o el path de fichero html local). 1.4.2 Extracción La función html_nodes acepta dos argumentos, ambos necesarios: html_nodes(x, css) El argumento x representa el código HTML importado mediante la función read_html El segundo argumento es un criterio de selección que utiliza la gramática de los selectores de CSS. Esta función devuelve una lista (matriz) de las ocurrencias encontradas en la pagina de acuerdo al criterio de selección. Así, el comando siguiente da la lista de las tablas incluidas en la pagina: html_nodes(amanece, &quot;table&quot;) ## {xml_nodeset (2)} ## [1] &lt;table class=&quot;cast_list&quot;&gt;\\n&lt;tr&gt;&lt;td colspan=&quot;4&quot; class=&quot;castlist_label ... ## [2] &lt;table class=&quot;footer&quot; id=&quot;amazon-affiliates&quot;&gt;\\n&lt;tr&gt;\\n&lt;td colspan=&quot;8&quot; ... 1.4.2.1 Extracción de texto Se puede también extraer su titulo titulo &lt;- html_node(amanece, &quot;title&quot;) html_text(titulo) ## [1] &quot;Amanece, que no es poco (1989) - IMDb&quot; Sólo hay una etiqueta “title” en una página, por lo que utilizaremos html_node() (sin la s final) en lugar de html_nodes(), porque sólo devuelve un elemento en vez de una lista. La función html_text elimina todas las etiquetas del código y muestra solo el contenido textual. Una opción muy útil de esta función es trim = TRUE que elimina los espacios antes y después del texto. Cabe mencionar, que mediante la gramática de “tuberias”, la secuencia anterior de comandos, puede ser expresada en una solo linea: amanece %&gt;% html_node(&quot;title&quot;) %&gt;% html_text() Descargar el ultimo discurso del rey de España desde la siguiente dirección: http://www.casareal.es/ES/Actividades/Paginas/actividades_discursos_detalle.aspx?data=5738 1.4.2.2 Extracción de tablas La función html_table, como su nombre indica, está especialmente diseñada para extraer los contenidos de una tabla HTML, manteniendo la estructura en filas y columnas- Así, el comando siguiente permite extraer la lista de actores de la película que viene en la segunda columna de la tabla con clase “cast_list”: html_node(amanece, &quot;table.cast_list&quot;) %&gt;% html_table(header=TRUE) %&gt;% .[[2]] # .[[2]] para segunda columna ## [1] &quot;José Sazatornil&quot; &quot;Carmen de Lirio&quot; &quot;Francisco Martínez&quot; ## [4] &quot;Ovidi Montllor&quot; &quot;Carmen Rodríguez&quot; &quot;Rafael Díaz&quot; ## [7] &quot;Amada Tercero&quot; &quot;Cassen&quot; &quot;Manuel Alexandre&quot; ## [10] &quot;María Ángeles Ariza&quot; &quot;Rafael Alonso&quot; &quot;Fedra Lorente&quot; ## [13] &quot;Cris Huerta&quot; &quot;Elisa Belmonte&quot; &quot;María I. González&quot; Descargar las cotizaciones del IBEX 35 en tiempo real desde la siguiente pagina ibex35 &lt;- “http://www.bolsamadrid.es/esp/aspx/Mercados/Precios.aspx?indice=ESI100000000” 1.4.2.3 Extracción de vinculos Para ilustrar este tipo de extracción, vamos a importar las direcciones de las paginas de los actores de la película. Empezamos importando todos los enlaces (etiqueta `&lt;a&gt;´de “ancla”) contenidos en una tabla: enlaces &lt;- html_nodes(amanece, &quot;table a&quot;) enlaces ## {xml_nodeset (41)} ## [1] &lt;a href=&quot;/name/nm0768574/?ref_=tt_cl_i1&quot;&gt;&lt;img height=&quot;44&quot; width=&quot;32 ... ## [2] &lt;a href=&quot;/name/nm0768574/?ref_=tt_cl_t1&quot; itemprop=&quot;url&quot;&gt; &lt;span clas ... ## [3] &lt;a href=&quot;/title/tt0094641/characters/nm0768574?ref_=tt_cl_t1&quot;&gt;Cabo ... ## [4] &lt;a href=&quot;/name/nm0513922/?ref_=tt_cl_i2&quot;&gt;&lt;img height=&quot;44&quot; width=&quot;32 ... ## [5] &lt;a href=&quot;/name/nm0513922/?ref_=tt_cl_t2&quot; itemprop=&quot;url&quot;&gt; &lt;span clas ... ## [6] &lt;a href=&quot;/name/nm1771790/?ref_=tt_cl_i3&quot;&gt;&lt;img height=&quot;44&quot; width=&quot;32 ... ## [7] &lt;a href=&quot;/name/nm1771790/?ref_=tt_cl_t3&quot; itemprop=&quot;url&quot;&gt; &lt;span clas ... ## [8] &lt;a href=&quot;/name/nm0600120/?ref_=tt_cl_i4&quot;&gt;&lt;img height=&quot;44&quot; width=&quot;32 ... ## [9] &lt;a href=&quot;/name/nm0600120/?ref_=tt_cl_t4&quot; itemprop=&quot;url&quot;&gt; &lt;span clas ... ## [10] &lt;a href=&quot;/name/nm1771909/?ref_=tt_cl_i5&quot;&gt;&lt;img height=&quot;44&quot; width=&quot;32 ... ## [11] &lt;a href=&quot;/name/nm1771909/?ref_=tt_cl_t5&quot; itemprop=&quot;url&quot;&gt; &lt;span clas ... ## [12] &lt;a href=&quot;/name/nm0246717/?ref_=tt_cl_i6&quot;&gt;&lt;img height=&quot;44&quot; width=&quot;32 ... ## [13] &lt;a href=&quot;/name/nm0246717/?ref_=tt_cl_t6&quot; itemprop=&quot;url&quot;&gt; &lt;span clas ... ## [14] &lt;a href=&quot;/name/nm1773519/?ref_=tt_cl_i7&quot;&gt;&lt;img height=&quot;44&quot; width=&quot;32 ... ## [15] &lt;a href=&quot;/name/nm1773519/?ref_=tt_cl_t7&quot; itemprop=&quot;url&quot;&gt; &lt;span clas ... ## [16] &lt;a href=&quot;/name/nm0144107/?ref_=tt_cl_i8&quot;&gt;&lt;img height=&quot;44&quot; width=&quot;32 ... ## [17] &lt;a href=&quot;/name/nm0144107/?ref_=tt_cl_t8&quot; itemprop=&quot;url&quot;&gt; &lt;span clas ... ## [18] &lt;a href=&quot;/title/tt0094641/characters/nm0144107?ref_=tt_cl_t8&quot;&gt;Cura ... ## [19] &lt;a href=&quot;/name/nm0018872/?ref_=tt_cl_i9&quot;&gt;&lt;img height=&quot;44&quot; width=&quot;32 ... ## [20] &lt;a href=&quot;/name/nm0018872/?ref_=tt_cl_t9&quot; itemprop=&quot;url&quot;&gt; &lt;span clas ... ## ... Luego extraemos las direcciones (atributo href) a las que apuntan dichos enlaces utilizando la función html_attr: actores &lt;- enlaces %&gt;% html_attr(&quot;href&quot;) raiz=&quot;http://www.imdb.com&quot; browseURL(paste(raiz,actores[1],sep=&quot;/&quot;)) #pagina de José Sazatornil 1.5 Navegación El paquete rvest proporciona también funciones para emular un navegador web. 1.5.1 Inición de la navegación Con la función html_sessionse crea un punto de entrada para la navegación. sesion &lt;- html_session(&quot;http://www.imdb.com&quot;) La variable “sesion” contiene ahora información de la página “visitada”. sesion ## &lt;session&gt; https://www.imdb.com/ ## Status: 200 ## Type: text/html;charset=UTF-8 ## Size: 195073 1.5.2 Funciones jump_to y follow_link Estas dos funciones tienen el mismo propósito, es decir, seguir un enlace para ir de una página a otra. La diferencia entre las dos funciones se refiere a la forma de referirse al enlace. La función jump_to toma una url (ya sea relativa o absoluta) sesion %&gt;% jump_to(&quot;boxoffice&quot;) %&gt;% session_history() ## https://www.imdb.com/ ## - https://www.imdb.com/chart/boxoffice Mientras que la función follow_link acepta la referencia a un enlace en una página en tres formas distintas: Un número cardinal (ej., “5” para la quinta etiqueta a presente en el HTML de la página). Un selector CSS (ej., “p a” para enlaces en un párrafo) Una palabra o frase que representa la etiqueta textual del enlace (ej. ) toma una expresión que hace referencia a un enlace (una etiqueta &lt;a&gt;) de la página: sesion %&gt;% follow_link(5) ## Navigating to /chart/toptv/?ref_=nv_tp_tv250_2 ## &lt;session&gt; https://www.imdb.com/chart/toptv/?ref_=nv_tp_tv250_2 ## Status: 200 ## Type: text/html;charset=UTF-8 ## Size: 572857 sesion %&gt;% follow_link(css = &quot;p a&quot;) #enlace en un parráfo ## Navigating to /movies-in-theaters/?ref_=nv_tp_inth_1 ## &lt;session&gt; https://www.imdb.com/movies-in-theaters/?ref_=nv_tp_inth_1 ## Status: 200 ## Type: text/html;charset=UTF-8 ## Size: 198262 sesion %&gt;% follow_link(&quot;Indian&quot;) ## Navigating to /india/top-rated-indian-movies?ref_=nv_mv_250_in_7 ## &lt;session&gt; https://www.imdb.com/india/top-rated-indian-movies/?ref_=nv_mv_250_in_7 ## Status: 200 ## Type: text/html;charset=UTF-8 ## Size: 592326 Cualquier movimiento con estas funciones se grabará en la sesión de navegación, de modo que se pueda realizar un seguimiento de la navegación. La función session_history muestra la cronología completa de las páginas visitadas en la misma sesión: sesion %&gt;% jump_to(&quot;boxoffice&quot;) %&gt;% session_history() ## https://www.imdb.com/ ## - https://www.imdb.com/chart/boxoffice 1.5.3 html_form(sesion) html_form(sesion) ## [[1]] ## &lt;form&gt; &#39;navbar-form&#39; (GET /find) ## &lt;button submit&gt; &#39;&lt;unnamed&gt; ## &lt;input hidden&gt; &#39;ref_&#39;: nv_sr_fn ## &lt;input text&gt; &#39;q&#39;: ## &lt;select&gt; &#39;s&#39; [0/6] ## ## [[2]] ## &lt;form&gt; &#39;ue_backdetect&#39; (GET get) ## &lt;input hidden&gt; &#39;ue_back&#39;: 1 Buscamos las películas con “amanece” en su título: busqueda &lt;-html_form(sesion)[[1]] %&gt;% set_values(`q` = &quot;amanece&quot;, s=&quot;Titles&quot;) busqueda %&gt;% submit_form(session=sesion) %&gt;% html_nodes(&quot;td.result_text&quot;) %&gt;% html_text() ## Submitting with &#39;&lt;unnamed&gt;&#39; ## [1] &quot; Le jour se lève (1939) aka \\&quot;Amanece\\&quot; &quot; ## [2] &quot; Amanece (2017) (Short) &quot; ## [3] &quot; Amanece (2010) (Short) &quot; ## [4] &quot; La saga Crepúsculo: Amanecer - Parte 2 (2012) &quot; ## [5] &quot; Amanda Jane Cooper (Actress, Selfie (2014))&quot; ## [6] &quot; Dan Eckman (Director, Checkout (2006))&quot; ## [7] &quot; breaking-a-man&#39;s-neck (4 titles) &quot; ## [8] &quot; andaman-sea (2 titles) &quot; ## [9] &quot; Amanecer Latino [es] (Production) &quot; ## [10] &quot; Amanecer Films [es] (Production) &quot; Extraer cotizaciones del ibex 35 utilizando navegación virtual. Inicio de sesión: cotiz &lt;- html_session(“http://www.bolsamadrid.es/esp/aspx/Mercados/Precios.aspx”) "],
["introduccion-a-la-mineria-de-texto.html", "2 Introducción a la minería de texto 2.1 Aplicaciones 2.2 Conceptos básicos 2.3 Manipulación y análisis básicos de texto 2.4 Creación de un Corpus con tidytext 2.5 Análisis de frecuencias de tokens", " 2 Introducción a la minería de texto 2.1 Aplicaciones La minería de texto nace de una combinación de minería de datos, análisis de texto cuantitativo y procesamiento automático del lenguaje. Las principales aplicaciones son: Motores de búsqueda Detección de plagio Clasificación de correo electrónico (detección de SPAM) Búsqueda de opiniones (evaluaciones positivas o negativas de un servicio, etc.) Organización de información (tipologías, ontologías) Traducción automática … 2.2 Conceptos básicos 2.2.1 Formato de los datos textuales Podemos distinguir tres tipos principales de textos: Tablas que consisten en filas y columnas Textos sin formato (extracción de pdf, …) Documentos semiestructurados (paginas web, correos electrónicos, RSS) 2.2.2 Unidad de análisis: el token Un token es una unidad significativa de texto, a menudo una palabra (o una secuencia de palabras, oración, ..), en la cual estamos interesados en utilizar para un análisis posterior. La tokenización es el proceso de dividir el texto en tokens y es uno de los primeros pasos del análisis de textos. 2.2.3 Preparación de los datos textuales Antes de poder utilizar métodos puramente cuantitativos de minería de textos, se debe preparar los documentos. Como regla general, pasamos por los siguientes pasos (no necesariamente en este orden preciso): Creación del corpus Limpieza y filtraje de la información relevante Análisis del texto e interpretación de los resultados 2.3 Manipulación y análisis básicos de texto Las tablas bajadas de Internet (y datos procedentes de otras fuentes) exigen frecuentemente un proceso de limpieza de datos o de extracción de la información que contienen. La función gsub se usa muy a menudo para dicha limpieza de datos. Una llamada a gsub tiene la forma gsub(&quot;h&quot;, &quot;H&quot;, c(&quot;hola&quot;, &quot;búho&quot;)) ## [1] &quot;Hola&quot; &quot;búHo&quot; donde el primer argumento, &quot;h&quot; es una expresión regular; la función gsub modifica las ocurrencias de esta expresión regular por el segundo argumento, &quot;H&quot; en este caso. El tercer argumento es un vector que contiene cadenas de texto en las que se realiza la sustitución. Las expresiones regulares son muy útiles para manipular texto. Conviene aprender algunas de las más frecuentes, como por ejemplo, las que identifican caracteres que aparecen al principio de un texto, gsub(&quot;^h&quot;, &quot;H&quot;, c(&quot;hola&quot;, &quot;búho&quot;)) ## [1] &quot;Hola&quot; &quot;búho&quot; o al final del mismo, gsub(&quot;o$&quot;, &quot;os&quot;, c(&quot;hola&quot;, &quot;búho&quot;)) ## [1] &quot;hola&quot; &quot;búhos&quot; Una función emparentada con gsub es grep, que busca cadenas en las que aparece una determinada expresión regular: grep(&quot;^h&quot;, c(&quot;hola&quot;, &quot;búho&quot;)) ## [1] 1 La salida de la expresión anterior nos indica que el patrón cadena de texto que comienza con la letra h aparece solo en la posición número 1 del vector. colors() es una función que devuelve el nombre de más de 600 colores en R. Usándolo, Encontrar * Aquellos cuyo nombre contenga un número (posiblemente tengas que investigar cómo se expresa cualquier número como expresión regular) * Aquellos que comiencen con yellow * Aquellos que contengan blue Los números que aparecen en la tabla descargada en la sección anterior (y contenidos en ibex) no tienen formato numérico. Para convertirlos en números de verdad, transfórmalos adecuadamente: Usar gsub para cambiar “.” por “” (i.e., nada) en las columnas de interés. Ten en cuenta que . es el comodín de las expresiones regulares; el punto es \\.. Usar gsub para cambiar , por . en las columnas de interés. Finalmente, usar as.numeric para cambiar texto resultante por valores numéricos. Otra función muy útil para procesar texto es paste, que tiene un comportamiento distinto según se use con el argumento sep o collapse. paste(&quot;A&quot;, 1:6, sep = &quot;,&quot;) ## [1] &quot;A,1&quot; &quot;A,2&quot; &quot;A,3&quot; &quot;A,4&quot; &quot;A,5&quot; &quot;A,6&quot; paste(&quot;Hoy es &quot;, date(), &quot; y tengo clase de R&quot;, sep = &quot;&quot;) ## [1] &quot;Hoy es Fri Jun 01 10:12:49 2018 y tengo clase de R&quot; paste(&quot;A&quot;, 1:6, collapse = &quot;,&quot;) ## [1] &quot;A 1,A 2,A 3,A 4,A 5,A 6&quot; sep y collapse pueden combinarse: paste(&quot;A&quot;, 1:6, sep = &quot;_&quot;, collapse = &quot;,&quot;) ## [1] &quot;A_1,A_2,A_3,A_4,A_5,A_6&quot; Para la operación inversa, la de partir cadenas de texto, se usa la función strsplit: strsplit(&quot;Hoy es martes&quot;, split = &quot; &quot;) ## [[1]] ## [1] &quot;Hoy&quot; &quot;es&quot; &quot;martes&quot; strsplit(c(&quot;hoy es martes&quot;, &quot;mañana es miércoles&quot;), split = &quot; &quot;) ## [[1]] ## [1] &quot;hoy&quot; &quot;es&quot; &quot;martes&quot; ## ## [[2]] ## [1] &quot;mañana&quot; &quot;es&quot; &quot;miércoles&quot; Advierte que esta función devuelve una lista de cadenas de texto. Crea una función que tome los nombres de ficheros ficheros &lt;- c(“ventas_20160522_zaragoza.csv”, “pedidos_firmes_20160422_soria.csv”) y genere una tabla con una fila por fichero y tres columnas: el nombre del fichero, la fecha y y la provincia. Nota: puedes crear una función que procese solo un nombre de fichero y aplicársela convenientemente al vector de nombres. Esas son las funciones fundamentales para la manipulación básica de texto en R. Existen funciones más ágiles en otros paquetes como stringro tidyr. A continuación una aplicación de uso del paquete stringr donde se describe como se distribuyen las Medallas Fields (el “nobel” en matemáticas) entre los países, utilizando la información proporcionada por la wikipedia. Empezamos extrayendo la tabla de interés desde la Wikipedia: require(rvest) mfield&lt;-read_html(&quot;https://es.wikipedia.org/w/index.php?title=Medalla_Fields&amp;oldid=103644843&quot;) mfield %&gt;% html_nodes(&quot;table&quot;) ## {xml_nodeset (2)} ## [1] &lt;table class=&quot;infobox&quot; style=&quot;width:22.7em; line-height: 1.4em; text ... ## [2] &lt;table class=&quot;wikitable&quot; border=&quot;1&quot;&gt;\\n&lt;tr&gt;\\n&lt;th&gt;Año&lt;/th&gt;\\n&lt;th&gt;Medall ... tabla &lt;- mfield %&gt;% html_nodes(&quot;table&quot;) %&gt;% .[[2]] %&gt;% html_table(header=TRUE) knitr:::kable(tabla %&gt;% head(10)) Año Medallistas 1936 Lars Ahlfors ( Finlandia), Universidad Harvard 1936 Jesse Douglas ( Estados Unidos), Instituto Tecnológico de Massachusetts 1950 Laurent Schwartz ( Francia), Universidad de Nancy 1950 Atle Selberg (Noruega), Instituto de Estudios Avanzados de Princeton 1954 Kunihiko Kodaira ( Japón), Universidad de Princeton 1954 Jean-Pierre Serre ( Francia), Universidad de París 1958 Klaus Friedrich Roth ( Reino Unido), Universidad de Londres 1958 René Thom ( Francia), Universidad de Estrasburgo 1962 Lars V. Hörmander (Suecia), Universidad de Estocolmo 1962 John Willard Milnor ( Estados Unidos), Universidad de Princeton Ahora, se extraen los países que vienen entre paréntesis usando expresiones regulares (ver ayuda de R sobre estas expresiones: require(tidyverse) tmp &lt;- tabla$Medallistas %&gt;% str_extract(&quot;\\\\([^()]+\\\\)&quot;) #extrae contenido entre parentesis tmp &lt;- substring(tmp,2,nchar(tmp)-1) paises&lt;- tmp %&gt;% str_split_fixed(&quot; y &quot;, 2) %&gt;% str_trim() %&gt;% c() Representación de distribución de medallas entre los países: freq=c(table(paises))[-1] #el -1 es para quitar la frecuencia de &quot;&quot; qplot(freq,reorder(names(freq),freq),ylab=&quot;paises&quot;) 2.4 Creación de un Corpus con tidytext El formato de texto tidy es básicamente una tabla con un token por fila. Este formato se presta muy bien a la minería de datos textuales. 2.4.1 Tokenización con la función unnest_tokens Aquí unas frases extraídas del libro “Niebla” de Unamuno: texto&lt;-c(&quot;Eso es insultar al lector, es llamarle torpe&quot;,&quot;Es decirle: ¡fíjate, hombre, fíjate, que aquí hay intención!&quot;,&quot;Y por eso le recomendaba yo a un señor que escribiese sus artículos todo en bastardilla&quot;,&quot;Para que el público se diese cuenta de que eran intencionadísimos desde la primera palabra a la última.&quot;) texto ## [1] &quot;Eso es insultar al lector, es llamarle torpe&quot; ## [2] &quot;Es decirle: ¡fíjate, hombre, fíjate, que aquí hay intención!&quot; ## [3] &quot;Y por eso le recomendaba yo a un señor que escribiese sus artículos todo en bastardilla&quot; ## [4] &quot;Para que el público se diese cuenta de que eran intencionadísimos desde la primera palabra a la última.&quot; Para analizar este tipo de información textual con tidytext, se le da un formato de tabla: require(tidyverse) texto_df &lt;- data_frame(fila = 1:4, texto = texto) texto_df ## # A tibble: 4 x 2 ## fila texto ## &lt;int&gt; &lt;chr&gt; ## 1 1 Eso es insultar al lector, es llamarle torpe ## 2 2 Es decirle: ¡fíjate, hombre, fíjate, que aquí hay intención! ## 3 3 Y por eso le recomendaba yo a un señor que escribiese sus artícul~ ## 4 4 Para que el público se diese cuenta de que eran intencionadísimos~ Todavía esta tabla no permite un análisis del texto. No podemos filtrar las palabras o calcular sus frecuencias, puesto que cada fila se compone de varias palabras combinadas. Necesitamos transformarla de manera que un token por fila . A menudo, el token es una secuencia de caracteres entre dos separadores. Un separador puede ser un “blanco”, una puntuación, un paréntesis, etc. Para segmentar el texto en tokens individuales y transformarlo en una estructura de datos utilizamos aquí la función ’unnest_tokensdel paquetetidytext`: require(tidytext) texto_df %&gt;% unnest_tokens(palabra, texto) ## # A tibble: 51 x 2 ## fila palabra ## &lt;int&gt; &lt;chr&gt; ## 1 1 eso ## 2 1 es ## 3 1 insultar ## 4 1 al ## 5 1 lector ## 6 1 es ## 7 1 llamarle ## 8 1 torpe ## 9 2 es ## 10 2 decirle ## # ... with 41 more rows Los dos argumentos básicos de esta función son nombres de columnas. Primero tenemos el nombre de la columna de salida que se creará cuando el texto se procese (‘palabra’ en este caso) y luego la columna de entrada de la que proviene el texto (‘texto’ en este caso). Esta función usa el paquete tokenizers para separar cada línea de texto en tokens. La tokenización predeterminada es para palabras, pero otras opciones incluyen caracteres, n-grams, oraciones, líneas, párrafos o expresiones regulares. A continuación extraemos bigramms que pueden ser muy útiles para identificar el idioma: require(tidytext) texto_df %&gt;% unnest_tokens(palabra, texto, token=&quot;ngrams&quot;, n=2) # bigramm ## # A tibble: 47 x 2 ## fila palabra ## &lt;int&gt; &lt;chr&gt; ## 1 1 eso es ## 2 1 es insultar ## 3 1 insultar al ## 4 1 al lector ## 5 1 lector es ## 6 1 es llamarle ## 7 1 llamarle torpe ## 8 2 es decirle ## 9 2 decirle fíjate ## 10 2 fíjate hombre ## # ... with 37 more rows Después de usar unnest_tokens, hemos dividido cada fila para que haya un token (palabra) en cada fila de la nueva base de datos; la tokenización predeterminada en unnest_tokens() es para palabras sueltas. Cabe mencionar que en el resultado: Se conservan otras columnas, como el número de la fila de cada palabra. La puntuación ha sido eliminada. Por defecto, los tokens están en minúsculas, lo que hace más fácil la comparación con otros textos (usar el to_lower = FALSE para desactivarlo). 2.4.2 Tokenización de la obra de Jane Austen Con el formato anterior se puede manejar varios documentos incluyéndolos en una única base. Para ilustrarlo, se considera el texto de las seis novelas publicadas por Jane Austen incluidas en el paquete janeaustenr. En este paquete, los textos vienen en filas que son parecidas a las líneas impresas en un libro físico. A continuación, se anota cada fila por su numero, el capitulo y libro al que pertenece. require(janeaustenr) libros &lt;- austen_books() %&gt;% group_by(book) %&gt;% mutate(linenumber = row_number(), chapter = cumsum(str_detect(text, regex(&quot;^chapter [[:digit:]ivxlc]&quot;, ignore_case=TRUE)))) %&gt;% ungroup() A partir de esta base de datos textuales ordenados, se puede generar corpus de tokens tal y como se hizo anteriormente mediante la función unnest_tokens: tokens &lt;- libros %&gt;% unnest_tokens(word, text) tokens ## # A tibble: 725,055 x 4 ## book linenumber chapter word ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 Sense &amp; Sensibility 1 0 sense ## 2 Sense &amp; Sensibility 1 0 and ## 3 Sense &amp; Sensibility 1 0 sensibility ## 4 Sense &amp; Sensibility 3 0 by ## 5 Sense &amp; Sensibility 3 0 jane ## 6 Sense &amp; Sensibility 3 0 austen ## 7 Sense &amp; Sensibility 5 0 1811 ## 8 Sense &amp; Sensibility 10 1 chapter ## 9 Sense &amp; Sensibility 10 1 1 ## 10 Sense &amp; Sensibility 13 1 the ## # ... with 725,045 more rows 2.5 Análisis de frecuencias de tokens Una pregunta recurrente en la minería de textos y el procesamiento del lenguaje natural es tener una idea global de su contenido. Para este propósito se puede proporcionar las palabras más frecuente incluidas en el texto. Sin embargo, hay palabras que ocurren muchas veces pero que no caracterizan el texto; en castellano, palabras como “del”, “es”, “para”, … Es por lo tanto, importante disponer de una lista de dichas palabras para eliminarlas antes del análisis. Estas palabras “inútiles” están incluidas en el paquete stopwords y se pueden quitar del corpus mediante la función anti_join. El propio paquete tidytextcontiene una base llamada stop_wordsde estas palabras, pero sólo en ingles. tokens &lt;- tokens %&gt;% anti_join(stop_words) Podemos ahora procurar caracterizar la obra de Jane Austeen calculando las frecuencias de las palabras incluidas en sus novelas: freq &lt;- tokens %&gt;% count(word, sort = TRUE) Y representar la distribución de las palabras más frecuentes: require(ggplot2) freq %&gt;% filter(n &gt; 600) %&gt;% mutate(word = reorder(word, n)) %&gt;% ggplot(aes(word, n)) + geom_col() + xlab(NULL) + coord_flip() O, mediante una nube de palabras utilizando el paquete wordcloud: require(wordcloud) wordcloud(words = freq$word, freq = freq$n, min.freq = 300, max.words=100, random.order=FALSE, rot.per=0.35, colors=brewer.pal(8, &quot;Dark2&quot;)) Otro enfoque es observar la frecuencia inversa de documentos (idf) para una palabra dada, que aumenta su peso si se usa en pocos documentos de la colección: Si \\(N\\) denota el número total de documentos y \\(N_p\\) el número de documentos que contienen la palabra \\(p\\), entonces el idf de dicha palabra es: \\[ \\mbox{idf} = - \\log\\left(\\frac{N_p}{N}\\right) \\] Esto se puede combinar con la frecuencia de la palabra tf para calcular el tf-idf de un término (producto de ìdfy tf), es decir, la frecuencia de una palabra multiplicado por su especificidad al documento. Por lo tanto, la medida tf-idf mide hasta que punto una palabra caracteriza un documento dado dentro de una colección (o corpus) al cual pertenece dicho documento. Si lo aplicamos a las novelas de Jane Austeen, obtenemos: book_words &lt;- austen_books() %&gt;% unnest_tokens(word, text) %&gt;% count(book, word, sort = TRUE) %&gt;% ungroup() freq_rel &lt;- book_words %&gt;% bind_tf_idf(word, book, n) freq_rel ## # A tibble: 40,379 x 6 ## book word n tf idf tf_idf ## &lt;fct&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Mansfield Park the 6206 0.0387 0. 0. ## 2 Mansfield Park to 5475 0.0341 0. 0. ## 3 Mansfield Park and 5438 0.0339 0. 0. ## 4 Emma to 5239 0.0325 0. 0. ## 5 Emma the 5201 0.0323 0. 0. ## 6 Emma and 4896 0.0304 0. 0. ## 7 Mansfield Park of 4778 0.0298 0. 0. ## 8 Pride &amp; Prejudice the 4331 0.0354 0. 0. ## 9 Emma of 4291 0.0267 0. 0. ## 10 Pride &amp; Prejudice to 4162 0.0341 0. 0. ## # ... with 40,369 more rows Podemos observar que para estas palabras de uso muy corriente idf es igual a cero. Para ver las palabras con una elevada importancia escribimos: freq_rel %&gt;% arrange(desc(tf_idf)) ## # A tibble: 40,379 x 6 ## book word n tf idf tf_idf ## &lt;fct&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Sense &amp; Sensibility elinor 623 0.00519 1.79 0.00931 ## 2 Sense &amp; Sensibility marianne 492 0.00410 1.79 0.00735 ## 3 Mansfield Park crawford 493 0.00307 1.79 0.00551 ## 4 Pride &amp; Prejudice darcy 373 0.00305 1.79 0.00547 ## 5 Persuasion elliot 254 0.00304 1.79 0.00544 ## 6 Emma emma 786 0.00488 1.10 0.00536 ## 7 Northanger Abbey tilney 196 0.00252 1.79 0.00452 ## 8 Emma weston 389 0.00242 1.79 0.00433 ## 9 Pride &amp; Prejudice bennet 294 0.00241 1.79 0.00431 ## 10 Persuasion wentworth 191 0.00228 1.79 0.00409 ## # ... with 40,369 more rows Y así podemos representar una caracterización de cada novela mediante dichas palabras: freq_rel %&gt;% arrange(desc(tf_idf)) %&gt;% mutate(word = factor(word, levels = rev(unique(word)))) %&gt;% group_by(book) %&gt;% top_n(15) %&gt;% ungroup() %&gt;% ggplot(aes(word, tf_idf, fill = book)) + geom_col(show.legend = FALSE) + labs(x = NULL, y = &quot;tf-idf&quot;) + facet_wrap(~book, ncol = 2, scales = &quot;free&quot;) + coord_flip() Caracterizar algunos capítulos de “Pride and Prejudice” mediante el indicador tf-idf. Descargar 20 discursos del rey de España y caracterizarlos. Utilizar la dirección siguiente donde data corresponde al número del discurso. http://www.casareal.es/ES/Actividades/Paginas/actividades_discursos_detalle.aspx?data=5738 De manera general, se puede importar libros mediante el proyecto Gutenberg y el paquete gutenbergr (Robinson, 2016). Así, se puede importar la novela “Niebla” de Unamuno, de la siguiente manera: require(gutenbergr) unamuno &lt;- gutenberg_works(title==&quot;Niebla\\n(Nivola)&quot;,languages=&quot;es&quot;)$gutenberg_id %&gt;% gutenberg_download() %&gt;% gutenberg_strip() #quita encabezado y pie de pagina "],
["referencias.html", "3 Referencias", " 3 Referencias Este curso está basado en los siguientes textos: R para profesionales de los datos, Carlos Bellosta, 2017, https://datanalytics.com/libro_r Text Mining with R, A Tidy Approach, Julia Silge and David Robinson, 2018, https://www.tidytextmining.com/tidytext.html Scraping HTML Text, Bradley Boehmke, 2015, http://bradleyboehmke.github.io/2015/12/scraping-html-text.html "]
]
